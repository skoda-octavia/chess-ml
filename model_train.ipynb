{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "aHicF8xg_gT5"
      },
      "outputs": [],
      "source": [
        "import chess.pgn\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fW_kAdOM_t8u",
        "outputId": "e7dbf72c-6e5f-4016-9cee-fca2e3f151de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "500\n",
            "1000\n",
            "1500\n",
            "2000\n",
            "2500\n",
            "3000\n",
            "3500\n",
            "4000\n",
            "4500\n",
            "5000\n"
          ]
        }
      ],
      "source": [
        "def board_to_matrix(board: chess.Board, move: chess.Move):\n",
        "    matrix_board = torch.zeros((6, 8, 8))\n",
        "    matrix_move = torch.zeros((8, 8))\n",
        "\n",
        "    for i in range(8):\n",
        "        for j in range(8):\n",
        "            piece = board.piece_at(chess.square(i, j))\n",
        "            if piece is not None:\n",
        "                piece_type = piece.piece_type\n",
        "                piece_color = piece.color\n",
        "                index = piece_type - 1\n",
        "                if piece_color == chess.WHITE:\n",
        "                    matrix_board[index, 7-j, i] = 1\n",
        "                else:\n",
        "                    matrix_board[index, 7-j, i] = -1\n",
        "                # print(matrix_board)\n",
        "    # if board.turn == chess.BLACK:\n",
        "    #     matrix_board *= -1\n",
        "    #     matrix_board = [torch.flip(matrix, dims=[0]) for matrix in matrix_board]\n",
        "\n",
        "    file = chess.square_file(move.from_square)\n",
        "    rank = chess.square_rank(move.from_square)\n",
        "    matrix_move[7-rank][file] = 1\n",
        "    # print(matrix_board)\n",
        "    return matrix_board.tolist(), matrix_move.tolist()\n",
        "\n",
        "def main():\n",
        "    pgn = open(\"full.pgn\")\n",
        "    cnt = 0\n",
        "    board_matrix, piece_matrix = [], []\n",
        "\n",
        "    while True:\n",
        "        game = chess.pgn.read_game(pgn)\n",
        "        if game is None:\n",
        "            break\n",
        "        cnt+=1\n",
        "        if cnt % 500 == 0:\n",
        "            print(cnt)\n",
        "\n",
        "        board = game.board()\n",
        "        for move in game.mainline_moves():\n",
        "          if board.turn == chess.WHITE:\n",
        "              matrix_board, matrix_move = board_to_matrix(board, move)\n",
        "              board_matrix.append(matrix_board)\n",
        "              piece_matrix.append(matrix_move)\n",
        "          board.push(move)\n",
        "\n",
        "\n",
        "    X = torch.tensor(board_matrix)\n",
        "    y = torch.tensor(piece_matrix)\n",
        "    torch.save(X, \"X.pt\")\n",
        "    torch.save(y, \"y.pt\")\n",
        "\n",
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5BiT_412nBa",
        "outputId": "46148861-1066-45a5-8f0d-5d449e298efe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "cuda\n",
            "Epoch [3000/300000], train_acc: 0.056809, test_acc: 0.055678\n",
            "Epoch [6000/300000], train_acc: 0.070778, test_acc: 0.070597\n",
            "Epoch [9000/300000], train_acc: 0.072766, test_acc: 0.073677\n",
            "Epoch [12000/300000], train_acc: 0.083726, test_acc: 0.082698\n",
            "Epoch [15000/300000], train_acc: 0.113024, test_acc: 0.109609\n",
            "Epoch [18000/300000], train_acc: 0.128385, test_acc: 0.123064\n",
            "Epoch [21000/300000], train_acc: 0.137690, test_acc: 0.128853\n",
            "Epoch [24000/300000], train_acc: 0.140497, test_acc: 0.129617\n",
            "Epoch [27000/300000], train_acc: 0.163296, test_acc: 0.145956\n",
            "Epoch [30000/300000], train_acc: 0.176888, test_acc: 0.157139\n",
            "Epoch [33000/300000], train_acc: 0.183917, test_acc: 0.162731\n",
            "Epoch [36000/300000], train_acc: 0.188733, test_acc: 0.164785\n",
            "Epoch [39000/300000], train_acc: 0.194336, test_acc: 0.168367\n",
            "Epoch [42000/300000], train_acc: 0.221094, test_acc: 0.191564\n",
            "Epoch [45000/300000], train_acc: 0.230847, test_acc: 0.199122\n",
            "Epoch [48000/300000], train_acc: 0.240153, test_acc: 0.206134\n",
            "Epoch [51000/300000], train_acc: 0.252265, test_acc: 0.218038\n",
            "Epoch [54000/300000], train_acc: 0.265966, test_acc: 0.229528\n",
            "Epoch [57000/300000], train_acc: 0.272093, test_acc: 0.235054\n",
            "Epoch [60000/300000], train_acc: 0.291900, test_acc: 0.248072\n",
            "Epoch [63000/300000], train_acc: 0.300555, test_acc: 0.254451\n",
            "Epoch [66000/300000], train_acc: 0.304329, test_acc: 0.260567\n",
            "Epoch [69000/300000], train_acc: 0.310713, test_acc: 0.261287\n",
            "Epoch [72000/300000], train_acc: 0.316561, test_acc: 0.263166\n",
            "Epoch [75000/300000], train_acc: 0.324272, test_acc: 0.270352\n",
            "Epoch [78000/300000], train_acc: 0.324414, test_acc: 0.268670\n",
            "Epoch [81000/300000], train_acc: 0.338356, test_acc: 0.280400\n",
            "Epoch [84000/300000], train_acc: 0.339131, test_acc: 0.282148\n",
            "Epoch [87000/300000], train_acc: 0.342255, test_acc: 0.281099\n",
            "Epoch [90000/300000], train_acc: 0.345744, test_acc: 0.283393\n",
            "Epoch [93000/300000], train_acc: 0.346694, test_acc: 0.285795\n",
            "Epoch [96000/300000], train_acc: 0.359467, test_acc: 0.298180\n",
            "Epoch [99000/300000], train_acc: 0.365469, test_acc: 0.301588\n",
            "Epoch [102000/300000], train_acc: 0.367233, test_acc: 0.303445\n",
            "Epoch [105000/300000], train_acc: 0.365895, test_acc: 0.300649\n",
            "Epoch [108000/300000], train_acc: 0.372961, test_acc: 0.303969\n",
            "Epoch [111000/300000], train_acc: 0.376756, test_acc: 0.309888\n",
            "Epoch [114000/300000], train_acc: 0.381480, test_acc: 0.311068\n",
            "Epoch [117000/300000], train_acc: 0.382092, test_acc: 0.310981\n",
            "Epoch [120000/300000], train_acc: 0.380808, test_acc: 0.310828\n",
            "Epoch [123000/300000], train_acc: 0.388727, test_acc: 0.314388\n",
            "Epoch [126000/300000], train_acc: 0.386706, test_acc: 0.311155\n",
            "Epoch [129000/300000], train_acc: 0.390802, test_acc: 0.317271\n",
            "Epoch [132000/300000], train_acc: 0.393936, test_acc: 0.316900\n",
            "Epoch [135000/300000], train_acc: 0.392762, test_acc: 0.316725\n",
            "Epoch [138000/300000], train_acc: 0.401205, test_acc: 0.320897\n",
            "Epoch [141000/300000], train_acc: 0.399774, test_acc: 0.322186\n",
            "Epoch [144000/300000], train_acc: 0.404842, test_acc: 0.325331\n",
            "Epoch [147000/300000], train_acc: 0.407982, test_acc: 0.327079\n",
            "Epoch [150000/300000], train_acc: 0.410177, test_acc: 0.327974\n",
            "Epoch [153000/300000], train_acc: 0.412935, test_acc: 0.327756\n",
            "Epoch [156000/300000], train_acc: 0.411799, test_acc: 0.328215\n",
            "Epoch [159000/300000], train_acc: 0.413666, test_acc: 0.330552\n",
            "Epoch [162000/300000], train_acc: 0.417576, test_acc: 0.330683\n",
            "Epoch [165000/300000], train_acc: 0.418008, test_acc: 0.327297\n",
            "Epoch [168000/300000], train_acc: 0.418800, test_acc: 0.329372\n",
            "Epoch [171000/300000], train_acc: 0.422944, test_acc: 0.331666\n",
            "Epoch [174000/300000], train_acc: 0.423414, test_acc: 0.331317\n",
            "Epoch [177000/300000], train_acc: 0.422999, test_acc: 0.328215\n",
            "Epoch [180000/300000], train_acc: 0.428192, test_acc: 0.333850\n",
            "Epoch [183000/300000], train_acc: 0.428372, test_acc: 0.333173\n",
            "Epoch [186000/300000], train_acc: 0.429459, test_acc: 0.332605\n",
            "Epoch [189000/300000], train_acc: 0.426008, test_acc: 0.332846\n",
            "Epoch [192000/300000], train_acc: 0.427641, test_acc: 0.331841\n",
            "Epoch [195000/300000], train_acc: 0.431403, test_acc: 0.332540\n",
            "Epoch [198000/300000], train_acc: 0.431715, test_acc: 0.334921\n",
            "Epoch [201000/300000], train_acc: 0.433631, test_acc: 0.333588\n",
            "Epoch [204000/300000], train_acc: 0.432359, test_acc: 0.330836\n",
            "Epoch [207000/300000], train_acc: 0.436455, test_acc: 0.336428\n",
            "Epoch [210000/300000], train_acc: 0.437678, test_acc: 0.335751\n",
            "Epoch [213000/300000], train_acc: 0.434510, test_acc: 0.333981\n",
            "Epoch [216000/300000], train_acc: 0.437126, test_acc: 0.332103\n",
            "Epoch [219000/300000], train_acc: 0.440845, test_acc: 0.337323\n",
            "Epoch [222000/300000], train_acc: 0.439420, test_acc: 0.332846\n",
            "Epoch [225000/300000], train_acc: 0.441118, test_acc: 0.336035\n",
            "Epoch [228000/300000], train_acc: 0.442533, test_acc: 0.336035\n",
            "Epoch [231000/300000], train_acc: 0.443963, test_acc: 0.336843\n",
            "Epoch [234000/300000], train_acc: 0.444548, test_acc: 0.336624\n",
            "Epoch [237000/300000], train_acc: 0.440714, test_acc: 0.333960\n"
          ]
        }
      ],
      "source": [
        "def test(device_str: str, eps_num: int, leraning_rate = 0.03):\n",
        "  X = torch.load(\"X.pt\")\n",
        "  y = torch.load(\"y.pt\")\n",
        "  assert len(X) == len(y)\n",
        "\n",
        "  ratio = 0.8\n",
        "  idx = int(X.size(0)*ratio)\n",
        "  device = torch.device(device_str if torch.cuda.is_available() else \"cpu\")\n",
        "  if device_str == \"cuda\":\n",
        "    X_train, X_test = X[:idx].to(device), X[idx:].to(device)\n",
        "    Y_train, Y_test = y[:idx].to(device), y[idx:].to(device)\n",
        "  else:\n",
        "    X_train, X_test = X[:idx], X[idx:]\n",
        "    Y_train, Y_test = y[:idx], y[idx:]\n",
        "  print(torch.cuda.is_available())\n",
        "  print(device)\n",
        "\n",
        "  model = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(8*8*6, 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64, 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64, 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64, 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64, 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64, 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64, 8*8),\n",
        "  ).to(device)\n",
        "\n",
        "  X_train.to(device)\n",
        "  X_test.to(device)\n",
        "  Y_train.to(device)\n",
        "  Y_test.to(device)\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.SGD(model.parameters(), lr=leraning_rate)\n",
        "  num_epochs = eps_num\n",
        "  eps = []\n",
        "  train_acc = []\n",
        "  test_acc = []\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    optimizer.zero_grad()\n",
        "    output = model(X_train.view(-1, 8*8*6))\n",
        "    loss = criterion(output, Y_train.view(-1, 8*8))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch+1) % 3000 == 0:\n",
        "      model.eval()\n",
        "      correct = 0\n",
        "      total = 0\n",
        "      with torch.no_grad():\n",
        "        val_inputs = X_test.view(-1, 8*8*6)\n",
        "        val_labels = Y_test.view(-1, 8*8)\n",
        "        val_outputs = model(val_inputs)\n",
        "        val_loss = criterion(val_outputs, val_labels)\n",
        "        max_idxs, predicted = torch.max(val_outputs, 1)\n",
        "        total = val_labels.size(0)\n",
        "        correct = torch.sum((val_labels[torch.arange(len(predicted)), predicted] == 1).float())\n",
        "        accuracy_test = correct / total\n",
        "\n",
        "        val_inputs = X_train.view(-1, 8*8*6)\n",
        "        val_labels = Y_train.view(-1, 8*8)\n",
        "        val_outputs = model(val_inputs)\n",
        "        val_loss = criterion(val_outputs, val_labels)\n",
        "        _, predicted = torch.max(val_outputs, 1)\n",
        "        total = val_labels.size(0)\n",
        "        correct = torch.sum((val_labels[torch.arange(len(predicted)), predicted] == 1).float())\n",
        "        accuracy_train = correct / total\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], train_acc: {accuracy_train:4f}, test_acc: {accuracy_test:4f}')\n",
        "        eps.append(epoch)\n",
        "        train_acc.append(accuracy_train.cpu().numpy())  # Konwersja tensora na numpy array\n",
        "        test_acc.append(accuracy_test.cpu().numpy()) \n",
        "\n",
        "  plt.plot(eps, train_acc, label=\"train_acc\")\n",
        "  plt.plot(eps, test_acc, label=\"test_acc\")\n",
        "  plt.xlabel(\"eps\")\n",
        "  plt.ylabel(\"accuracy\")\n",
        "  plt.legend()\n",
        "  plt.title(f\"Accuracy, lr: {leraning_rate}\")\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  # current_time = datetime.datetime.now()\n",
        "  eps = 300000\n",
        "  test(\"cuda\", eps)\n",
        "  # end = datetime.datetime.now()\n",
        "  # print(f\"cuda {eps} eps: {end-current_time}\")\n",
        "  # current_time = datetime.datetime.now()\n",
        "  # test(\"cpu\", 100)\n",
        "  # end = datetime.datetime.now()\n",
        "  # print(f\"cuda 100 eps: {end-current_time}\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
