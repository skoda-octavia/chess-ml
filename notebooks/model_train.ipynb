{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aHicF8xg_gT5"
      },
      "outputs": [],
      "source": [
        "import chess.pgn\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fW_kAdOM_t8u",
        "outputId": "e7dbf72c-6e5f-4016-9cee-fca2e3f151de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "500\n",
            "1000\n",
            "1500\n",
            "2000\n",
            "2500\n",
            "3000\n",
            "3500\n",
            "4000\n",
            "4500\n",
            "5000\n"
          ]
        }
      ],
      "source": [
        "def board_to_matrix(board: chess.Board, move: chess.Move):\n",
        "    matrix_board = torch.zeros((6, 8, 8))\n",
        "    matrix_move = torch.zeros((8, 8))\n",
        "\n",
        "    for i in range(8):\n",
        "        for j in range(8):\n",
        "            piece = board.piece_at(chess.square(i, j))\n",
        "            if piece is not None:\n",
        "                piece_type = piece.piece_type\n",
        "                piece_color = piece.color\n",
        "                index = piece_type - 1\n",
        "                if piece_color == chess.WHITE:\n",
        "                    matrix_board[index, 7-j, i] = 1\n",
        "                else:\n",
        "                    matrix_board[index, 7-j, i] = -1\n",
        "                # print(matrix_board)\n",
        "    # if board.turn == chess.BLACK:\n",
        "    #     matrix_board *= -1\n",
        "    #     matrix_board = [torch.flip(matrix, dims=[0]) for matrix in matrix_board]\n",
        "\n",
        "    file = chess.square_file(move.from_square)\n",
        "    rank = chess.square_rank(move.from_square)\n",
        "    matrix_move[7-rank][file] = 1\n",
        "    # print(matrix_board)\n",
        "    return matrix_board.tolist(), matrix_move.tolist()\n",
        "\n",
        "def main():\n",
        "    pgn = open(\"full.pgn\")\n",
        "    cnt = 0\n",
        "    board_matrix, piece_matrix = [], []\n",
        "\n",
        "    while True:\n",
        "        game = chess.pgn.read_game(pgn)\n",
        "        if game is None:\n",
        "            break\n",
        "        cnt+=1\n",
        "        if cnt % 500 == 0:\n",
        "            print(cnt)\n",
        "\n",
        "        board = game.board()\n",
        "        for move in game.mainline_moves():\n",
        "          if board.turn == chess.WHITE:\n",
        "              matrix_board, matrix_move = board_to_matrix(board, move)\n",
        "              board_matrix.append(matrix_board)\n",
        "              piece_matrix.append(matrix_move)\n",
        "          board.push(move)\n",
        "\n",
        "\n",
        "    X = torch.tensor(board_matrix)\n",
        "    y = torch.tensor(piece_matrix)\n",
        "    torch.save(X, \"X.pt\")\n",
        "    torch.save(y, \"y.pt\")\n",
        "\n",
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5BiT_412nBa",
        "outputId": "46148861-1066-45a5-8f0d-5d449e298efe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "cuda\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (67492x448 and 384x64)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\Użytkownik\\Desktop\\inzynierskie-wypociny\\model_train.ipynb Cell 3\u001b[0m line \u001b[0;36m9\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/U%C5%BCytkownik/Desktop/inzynierskie-wypociny/model_train.ipynb#W2sZmlsZQ%3D%3D?line=94'>95</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/U%C5%BCytkownik/Desktop/inzynierskie-wypociny/model_train.ipynb#W2sZmlsZQ%3D%3D?line=95'>96</a>\u001b[0m   \u001b[39m# current_time = datetime.datetime.now()\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/U%C5%BCytkownik/Desktop/inzynierskie-wypociny/model_train.ipynb#W2sZmlsZQ%3D%3D?line=96'>97</a>\u001b[0m   eps \u001b[39m=\u001b[39m \u001b[39m2000\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/U%C5%BCytkownik/Desktop/inzynierskie-wypociny/model_train.ipynb#W2sZmlsZQ%3D%3D?line=97'>98</a>\u001b[0m   test(\u001b[39m\"\u001b[39;49m\u001b[39mcuda\u001b[39;49m\u001b[39m\"\u001b[39;49m, eps)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/U%C5%BCytkownik/Desktop/inzynierskie-wypociny/model_train.ipynb#W2sZmlsZQ%3D%3D?line=98'>99</a>\u001b[0m   \u001b[39m# end = datetime.datetime.now()\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/U%C5%BCytkownik/Desktop/inzynierskie-wypociny/model_train.ipynb#W2sZmlsZQ%3D%3D?line=99'>100</a>\u001b[0m   \u001b[39m# print(f\"cuda {eps} eps: {end-current_time}\")\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/U%C5%BCytkownik/Desktop/inzynierskie-wypociny/model_train.ipynb#W2sZmlsZQ%3D%3D?line=100'>101</a>\u001b[0m   \u001b[39m# current_time = datetime.datetime.now()\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/U%C5%BCytkownik/Desktop/inzynierskie-wypociny/model_train.ipynb#W2sZmlsZQ%3D%3D?line=101'>102</a>\u001b[0m   \u001b[39m# test(\"cpu\", 100)\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/U%C5%BCytkownik/Desktop/inzynierskie-wypociny/model_train.ipynb#W2sZmlsZQ%3D%3D?line=102'>103</a>\u001b[0m   \u001b[39m# end = datetime.datetime.now()\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/U%C5%BCytkownik/Desktop/inzynierskie-wypociny/model_train.ipynb#W2sZmlsZQ%3D%3D?line=103'>104</a>\u001b[0m   \u001b[39m# print(f\"cuda 100 eps: {end-current_time}\")\u001b[39;00m\n",
            "\u001b[1;32mc:\\Users\\Użytkownik\\Desktop\\inzynierskie-wypociny\\model_train.ipynb Cell 3\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/U%C5%BCytkownik/Desktop/inzynierskie-wypociny/model_train.ipynb#W2sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/U%C5%BCytkownik/Desktop/inzynierskie-wypociny/model_train.ipynb#W2sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m   optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/U%C5%BCytkownik/Desktop/inzynierskie-wypociny/model_train.ipynb#W2sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m   output \u001b[39m=\u001b[39m model(X_train\u001b[39m.\u001b[39;49mview(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m8\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39m8\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39m7\u001b[39;49m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/U%C5%BCytkownik/Desktop/inzynierskie-wypociny/model_train.ipynb#W2sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m   loss \u001b[39m=\u001b[39m criterion(output, Y_train\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m8\u001b[39m\u001b[39m*\u001b[39m\u001b[39m8\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/U%C5%BCytkownik/Desktop/inzynierskie-wypociny/model_train.ipynb#W2sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m   loss\u001b[39m.\u001b[39mbackward()\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
            "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (67492x448 and 384x64)"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "def test(device_str: str, eps_num: int, leraning_rate = 0.03):\n",
        "  x_file = \"X_rook.pt\"\n",
        "  y_file = \"Y_rook.pt\"\n",
        "  model_file = \"model_rook.pth\"\n",
        "  X = torch.load(x_file)\n",
        "  y = torch.load(y_file)\n",
        "  assert len(X) == len(y)\n",
        "\n",
        "  ratio = 0.8\n",
        "  idx = int(X.size(0)*ratio)\n",
        "  device = torch.device(device_str if torch.cuda.is_available() else \"cpu\")\n",
        "  if device_str == \"cuda\":\n",
        "    X_train, X_test = X[:idx].to(device), X[idx:].to(device)\n",
        "    Y_train, Y_test = y[:idx].to(device), y[idx:].to(device)\n",
        "  else:\n",
        "    X_train, X_test = X[:idx], X[idx:]\n",
        "    Y_train, Y_test = y[:idx], y[idx:]\n",
        "  print(torch.cuda.is_available())\n",
        "  print(device)\n",
        "\n",
        "  model = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(8*8*6, 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64, 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64, 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64, 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64, 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64, 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64, 8*8),\n",
        "  ).to(device)\n",
        "\n",
        "  X_train.to(device)\n",
        "  X_test.to(device)\n",
        "  Y_train.to(device)\n",
        "  Y_test.to(device)\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.SGD(model.parameters(), lr=leraning_rate)\n",
        "  num_epochs = eps_num\n",
        "  eps = []\n",
        "  train_acc = []\n",
        "  test_acc = []\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    optimizer.zero_grad()\n",
        "    output = model(X_train.view(-1, 8*8*7))\n",
        "    loss = criterion(output, Y_train.view(-1, 8*8))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch+1) % 30 == 0:\n",
        "      model.eval()\n",
        "      correct = 0\n",
        "      total = 0\n",
        "      with torch.no_grad():\n",
        "        val_inputs = X_test.view(-1, 8*8*7)\n",
        "        val_labels = Y_test.view(-1, 8*8)\n",
        "        val_outputs = model(val_inputs)\n",
        "        val_loss = criterion(val_outputs, val_labels)\n",
        "        max_idxs, predicted = torch.max(val_outputs, 1)\n",
        "        total = val_labels.size(0)\n",
        "        correct = torch.sum((val_labels[torch.arange(len(predicted)), predicted] == 1).float())\n",
        "        accuracy_test = correct / total\n",
        "\n",
        "        val_inputs = X_train.view(-1, 8*8*7)\n",
        "        val_labels = Y_train.view(-1, 8*8)\n",
        "        val_outputs = model(val_inputs)\n",
        "        val_loss = criterion(val_outputs, val_labels)\n",
        "        _, predicted = torch.max(val_outputs, 1)\n",
        "        total = val_labels.size(0)\n",
        "        correct = torch.sum((val_labels[torch.arange(len(predicted)), predicted] == 1).float())\n",
        "        accuracy_train = correct / total\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], train_acc: {accuracy_train:4f}, test_acc: {accuracy_test:4f}')\n",
        "        eps.append(epoch)\n",
        "        train_acc.append(accuracy_train.cpu().numpy())  # Konwersja tensora na numpy array\n",
        "        test_acc.append(accuracy_test.cpu().numpy()) \n",
        "\n",
        "  torch.save(model.state_dict(), 'model.pth')\n",
        "  plt.plot(eps, train_acc, label=\"train_acc\")\n",
        "  plt.plot(eps, test_acc, label=\"test_acc\")\n",
        "  plt.xlabel(\"eps\")\n",
        "  plt.ylabel(\"accuracy\")\n",
        "  plt.legend()\n",
        "  plt.title(f\"Accuracy, lr: {leraning_rate}\")\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  # current_time = datetime.datetime.now()\n",
        "  eps = 2000\n",
        "  test(\"cuda\", eps)\n",
        "  # end = datetime.datetime.now()\n",
        "  # print(f\"cuda {eps} eps: {end-current_time}\")\n",
        "  # current_time = datetime.datetime.now()\n",
        "  # test(\"cpu\", 100)\n",
        "  # end = datetime.datetime.now()\n",
        "  # print(f\"cuda 100 eps: {end-current_time}\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
