{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "import chess.pgn\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_games_from_file(file_path):\n",
    "    games = []\n",
    "    with open(file_path, 'r') as pgn_file:\n",
    "        while True:\n",
    "            try:\n",
    "                game = chess.pgn.read_game(pgn_file)\n",
    "                if game is None:\n",
    "                    break\n",
    "                games.append(game)\n",
    "            except ValueError as e:\n",
    "                print(f\"Pominięto partię z powodu błędu: {e}\")\n",
    "    return games\n",
    "\n",
    "def is_checkmate(game):\n",
    "    board = game.board()\n",
    "    for move in game.mainline_moves():\n",
    "        board.push(move)\n",
    "    return board.is_checkmate()\n",
    "\n",
    "def filter_checkmate_games(games, pgn_output_path):\n",
    "    checkmate_games = []\n",
    "    for cnt, game in enumerate(games):\n",
    "        try:\n",
    "            if is_checkmate(game):\n",
    "                checkmate_games.append(game)\n",
    "        except Exception as e:\n",
    "            print(f\"Pominięto partię numer {cnt} z powodu błędu: {e}\")\n",
    "\n",
    "    with open(pgn_output_path, \"a\") as output_file:\n",
    "        for game in checkmate_games:\n",
    "            output_file.write(str(game))\n",
    "            output_file.write(\"\\n\\n\")\n",
    "\n",
    "\n",
    "data_path = \"../data/raw/\"\n",
    "files = os.listdir(data_path)\n",
    "for file in files:\n",
    "    games = read_games_from_file(data_path + file)\n",
    "    filter_checkmate_games(games, data_path + \"mates.pgn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/51366\n",
      "1000/51366\n",
      "2000/51366\n",
      "3000/51366\n",
      "4000/51366\n",
      "5000/51366\n",
      "6000/51366\n",
      "7000/51366\n",
      "8000/51366\n",
      "9000/51366\n",
      "10000/51366\n",
      "11000/51366\n",
      "12000/51366\n",
      "13000/51366\n",
      "14000/51366\n",
      "15000/51366\n",
      "16000/51366\n",
      "17000/51366\n",
      "18000/51366\n",
      "19000/51366\n",
      "20000/51366\n",
      "21000/51366\n",
      "22000/51366\n",
      "23000/51366\n",
      "24000/51366\n",
      "25000/51366\n",
      "26000/51366\n",
      "27000/51366\n",
      "28000/51366\n",
      "29000/51366\n",
      "30000/51366\n",
      "31000/51366\n",
      "32000/51366\n",
      "33000/51366\n",
      "34000/51366\n",
      "35000/51366\n",
      "36000/51366\n",
      "37000/51366\n",
      "38000/51366\n",
      "39000/51366\n",
      "40000/51366\n",
      "41000/51366\n",
      "42000/51366\n",
      "43000/51366\n",
      "44000/51366\n",
      "45000/51366\n",
      "46000/51366\n",
      "47000/51366\n",
      "48000/51366\n",
      "49000/51366\n",
      "50000/51366\n",
      "51000/51366\n",
      "invalid:  244\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../data/raw/\"\n",
    "games = read_games_from_file(data_path+\"mates.pgn\")\n",
    "\n",
    "invalid = 0\n",
    "for cnt, game in enumerate(games):\n",
    "    data = []\n",
    "    board = chess.Board()\n",
    "    cor = True\n",
    "\n",
    "    for move in game.mainline_moves():\n",
    "        legal_moves = list(board.legal_moves)\n",
    "        legals_str = [\n",
    "            [chess.square_name(move_.from_square),chess.square_name(move_.to_square)]\n",
    "             for move_ in legal_moves if move_.promotion is None or move_.promotion == chess.QUEEN]\n",
    "        if move in legal_moves:\n",
    "            board_fen = board.fen()\n",
    "            *fen_data, _, __ = board_fen.split(\" \")\n",
    "            fen_data.append(move.uci())\n",
    "            fen_data.append(str(legals_str))\n",
    "            data.append(\",\".join(fen_data)+\"\\n\")\n",
    "            board.push(move)\n",
    "        else:\n",
    "            cor = False\n",
    "            invalid += 1\n",
    "            break\n",
    "    if cor:\n",
    "        with open(data_path+\"fen_data64.txt\", \"a\") as f:\n",
    "            f.writelines(data)\n",
    "    if cnt % 1000 == 0:\n",
    "        print(f\"{cnt}/{len(games)}\")\n",
    "print(\"invalid: \", invalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000000\n",
      "2000000\n",
      "3000000\n",
      "4000000\n",
      "5000000\n",
      "6000000\n",
      "7000000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_path = \"../data/raw/\"\n",
    "with open(data_path+\"fen_data64.txt\", \"r\") as f:\n",
    "    fens = f.readlines()\n",
    "max_move_cnt = 0\n",
    "\n",
    "for cnt, fen in enumerate(fens):\n",
    "    if \"k\" not in fen or \"K\" not in fen:\n",
    "        print (fen)\n",
    "        print (cnt)\n",
    "    list_idx = fen.index(\"[\")\n",
    "    list_str = fen[list_idx:-1]\n",
    "    len_ = list_str.count(\"[\")\n",
    "    max_move_cnt = max(max_move_cnt, len_ - 1)\n",
    "    if cnt % 1000000 == 0:\n",
    "        print(cnt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_move_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "1300000\n",
      "1400000\n",
      "1500000\n",
      "1600000\n",
      "1700000\n",
      "1800000\n",
      "1900000\n",
      "2000000\n",
      "2100000\n",
      "2200000\n",
      "2300000\n",
      "2400000\n",
      "2500000\n",
      "2600000\n",
      "2700000\n",
      "2800000\n",
      "2900000\n",
      "3000000\n",
      "3100000\n",
      "3200000\n",
      "3300000\n",
      "3400000\n",
      "3500000\n",
      "3600000\n",
      "3700000\n",
      "3800000\n",
      "3900000\n",
      "4000000\n",
      "4100000\n",
      "4200000\n",
      "4300000\n",
      "4400000\n",
      "4500000\n",
      "4600000\n",
      "4700000\n",
      "4800000\n",
      "4900000\n",
      "5000000\n",
      "5100000\n",
      "5200000\n",
      "5300000\n",
      "5400000\n",
      "5500000\n",
      "5600000\n",
      "5700000\n",
      "5800000\n",
      "5900000\n",
      "6000000\n",
      "6100000\n",
      "6200000\n",
      "6300000\n",
      "6400000\n",
      "6500000\n",
      "6600000\n",
      "6700000\n",
      "6800000\n",
      "6900000\n",
      "7000000\n",
      "7100000\n",
      "7200000\n",
      "7300000\n",
      "7400000\n",
      "7500000\n",
      "7600000\n",
      "7700000\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "import ast\n",
    "prep_tokenized_path = \"../data/prep/tokenized64.csv\"\n",
    "to_tokenize_path = \"../data/raw/fen_data64.txt\"\n",
    "vocab_src_path = \"../src/lstm64/vocab_src.json\"\n",
    "vocab_tar_path = \"../src/lstm64/vocab_tar.json\"\n",
    "cnt = 0\n",
    "\n",
    "with open(vocab_tar_path, \"r\") as f:\n",
    "    vocab_tar = json.load(f)\n",
    "\n",
    "with open(vocab_src_path, \"r\") as f:\n",
    "    vocab_src = json.load(f)\n",
    "\n",
    "with open(to_tokenize_path, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "nums = [8, 7, 6, 5, 4, 3, 2]\n",
    "\n",
    "with open(prep_tokenized_path, \"w\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['sequence', 'target', 'legal'])\n",
    "    for idx, line in enumerate(lines):\n",
    "        seq_token = [vocab_src['SOS']]\n",
    "        tar_token = [vocab_tar['SOS']]\n",
    "        fen, turn, cas, en_pass, tar, *legals_str = line.split(\",\")\n",
    "        \n",
    "        for num in nums:\n",
    "            fen = fen.replace(str(num), num * \"1\")\n",
    "        seq_token.extend([vocab_src[char] for char in fen])\n",
    "\n",
    "        turn_str = \"True\" if turn == \"w\" else \"False\"\n",
    "        seq_token.append(vocab_src[turn_str])\n",
    "\n",
    "        if cas != \"-\":\n",
    "            cas = cas.replace(\"K\", \"Ki\")\n",
    "            cas = cas.replace(\"Q\", \"Qu\")\n",
    "            cas = cas.replace(\"k\", \"ki\")\n",
    "            cas = cas.replace(\"q\", \"qu\")\n",
    "            elems = [cas[i:i+2] for i in range(0, len(cas), 2)]\n",
    "            seq_token.extend([vocab_src[cr] for cr in elems])\n",
    "\n",
    "        if en_pass != \"-\":\n",
    "            en = en_pass[0] + \"_enpas\"\n",
    "            seq_token.append(vocab_src[en])\n",
    "            seq_token.append(vocab_src[\"EOS\"])\n",
    "    \n",
    "        from_, to = tar[0:2], tar[2:4]\n",
    "        tar_token.append(vocab_tar[from_])\n",
    "        tar_token.append(vocab_tar[to])\n",
    "        if len(tar) == 5:\n",
    "            tar_token.append(vocab_tar[tar[4]])\n",
    "        tar_token.append(vocab_tar[\"EOS\"])\n",
    "        \n",
    "        legals_str = \",\".join(legals_str)\n",
    "        legals_str = legals_str[:-1]\n",
    "        # legals_str = legals_str.replace(\"'\", '\"')\n",
    "        legals = ast.literal_eval(legals_str)\n",
    "        legals = [[vocab_tar[from_], vocab_tar[to]] for from_, to in legals]\n",
    "        while len(legals) != max_move_cnt:\n",
    "            legals.append([-1, -1])\n",
    "        if cnt % 100000 == 0:\n",
    "            print(cnt)\n",
    "\n",
    "        cnt += 1\n",
    "        writer.writerow([seq_token, tar_token, legals])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
