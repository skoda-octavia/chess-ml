{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Rddg0QzILOY",
        "outputId": "a176610f-0448-4f1b-ba51-101fc657278b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import pandas as pd\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "import chess\n",
        "import ast\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch.optim as optim\n",
        "\n",
        "import math\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5Uk1gObhe5o"
      },
      "outputs": [],
      "source": [
        "class SequenceDataset(Dataset):\n",
        "    def __init__(self, src_sequences, tar_sequences, src_padd_idx, tar_padd_idx, max_src_len, max_tar_len):\n",
        "        self.src_sequences = [torch.tensor(seq) for seq in src_sequences]\n",
        "        self.tar_sequences = [torch.tensor(seq) for seq in tar_sequences]\n",
        "        self.src_padd_idx = src_padd_idx\n",
        "        self.tar_padd_idx = tar_padd_idx\n",
        "        self.max_src_len = max_src_len\n",
        "        self.max_tar_len = max_tar_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.src_sequences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        src_seq = self.src_sequences[idx]\n",
        "        tar_seq = self.tar_sequences[idx]\n",
        "\n",
        "        src_seq = torch.nn.functional.pad(src_seq, (0, self.max_src_len - len(src_seq)), value=self.src_padd_idx)\n",
        "        tar_seq = torch.nn.functional.pad(tar_seq, (0, self.max_tar_len - len(tar_seq)), value=self.tar_padd_idx)\n",
        "\n",
        "        return src_seq, tar_seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtIvP5MijOlX"
      },
      "outputs": [],
      "source": [
        "def load_data(csv_path, test_size=0.2, random_state=42):\n",
        "    df = pd.read_csv(csv_path)\n",
        "    sequences = df['sequence'].apply(ast.literal_eval).tolist()\n",
        "    targets = df['target'].apply(ast.literal_eval).tolist()\n",
        "    seq_train, seq_val, tar_train, tar_val = train_test_split(\n",
        "        sequences, targets, test_size=test_size, random_state=random_state\n",
        "    )\n",
        "    return seq_train, seq_val, tar_train, tar_val\n",
        "\n",
        "\n",
        "def find_max_length(sequences):\n",
        "    return max(len(seq) for seq in sequences)\n",
        "\n",
        "csv_path = 'tokenized.csv'\n",
        "src_padd_idx = 46\n",
        "tar_padd_idx = 70\n",
        "batch=128\n",
        "\n",
        "seq_train, seq_val, tar_train, tar_val = load_data(csv_path)\n",
        "\n",
        "max_src_len = max(find_max_length(seq_train), find_max_length(seq_val))\n",
        "max_tar_len = max(find_max_length(tar_train), find_max_length(tar_val))\n",
        "\n",
        "dataset_train = SequenceDataset(seq_train, tar_train, src_padd_idx, tar_padd_idx, max_src_len, max_tar_len)\n",
        "dataset_val = SequenceDataset(seq_val, tar_val, src_padd_idx, tar_padd_idx, max_src_len, max_tar_len)\n",
        "\n",
        "dataloader_train = DataLoader(dataset_train, batch_size=batch, shuffle=True, drop_last=True)\n",
        "dataloader_val = DataLoader(dataset_val, batch_size=batch, shuffle=True, drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cC9oPyx5KBzX"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, dim_model, dropout_p, max_len):\n",
        "        super().__init__()\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "        pos_encoding = torch.zeros(max_len, dim_model)\n",
        "        positions_list = torch.arange(0, max_len, dtype=torch.float).view(-1, 1)\n",
        "        division_term = torch.exp(torch.arange(0, dim_model, 2).float() * (-math.log(10000.0)) / dim_model)\n",
        "\n",
        "        pos_encoding[:, 0::2] = torch.sin(positions_list * division_term)\n",
        "\n",
        "        pos_encoding[:, 1::2] = torch.cos(positions_list * division_term)\n",
        "\n",
        "        pos_encoding = pos_encoding.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer(\"pos_encoding\",pos_encoding)\n",
        "\n",
        "    def forward(self, token_embedding: torch.tensor) -> torch.tensor:\n",
        "        seq_len = token_embedding.size(0)\n",
        "        batch_size = token_embedding.size(1)\n",
        "        pos_encoding = self.pos_encoding[:seq_len, :].expand(seq_len, batch_size, -1)\n",
        "        return self.dropout(token_embedding + pos_encoding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iti0ocTEYK65"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        src_num_tokens,\n",
        "        tar_num_tokens,\n",
        "        embed_size,\n",
        "        num_heads,\n",
        "        num_encoder_layers,\n",
        "        num_decoder_layers,\n",
        "        dropout_p,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.model_type = \"Transformer\"\n",
        "        self.embed_size = embed_size\n",
        "\n",
        "        self.positional_encoder = PositionalEncoding(\n",
        "            dim_model=embed_size, dropout_p=dropout_p, max_len=5000\n",
        "        )\n",
        "\n",
        "        self.src_embedding = nn.Embedding(src_num_tokens, embed_size)\n",
        "        self.tar_embedding = nn.Embedding(tar_num_tokens, embed_size)\n",
        "        self.transformer = nn.Transformer(\n",
        "            d_model=embed_size,\n",
        "            nhead=num_heads,\n",
        "            num_encoder_layers=num_encoder_layers,\n",
        "            num_decoder_layers=num_decoder_layers,\n",
        "            dropout=dropout_p,\n",
        "        )\n",
        "        self.out = nn.Linear(embed_size, tar_num_tokens)\n",
        "\n",
        "    def forward(self, src, tgt, tgt_mask=None, src_pad_mask=None, tgt_pad_mask=None):\n",
        "        src = self.src_embedding(src) * math.sqrt(self.embed_size)\n",
        "        tgt = self.tar_embedding(tgt) * math.sqrt(self.embed_size)\n",
        "        src = self.positional_encoder(src)\n",
        "        tgt = self.positional_encoder(tgt)\n",
        "\n",
        "        src = src.permute(1,0,2)\n",
        "        tgt = tgt.permute(1,0,2)\n",
        "\n",
        "        transformer_out = self.transformer(src, tgt, tgt_mask=tgt_mask, src_key_padding_mask=src_pad_mask, tgt_key_padding_mask=tgt_pad_mask)\n",
        "        out = self.out(transformer_out)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def get_tgt_mask(self, size) -> torch.tensor:\n",
        "        mask = torch.tril(torch.ones(size, size) == 1)\n",
        "        mask = mask.float()\n",
        "        mask = mask.masked_fill(mask == 0, float('-inf'))\n",
        "        mask = mask.masked_fill(mask == 1, float(0.0))\n",
        "        return mask\n",
        "\n",
        "    def create_pad_mask(self, matrix: torch.tensor, pad_token: int) -> torch.tensor:\n",
        "        return (matrix == pad_token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FEwKBQPAks7u"
      },
      "outputs": [],
      "source": [
        "def train_loop(model, opt, loss_fn, dataloader):\n",
        "\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in dataloader:\n",
        "        X, y = batch\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        y_input = y[:,:-1]\n",
        "        y_expected = y[:,1:]\n",
        "\n",
        "        sequence_length = y_input.size(1)\n",
        "        tgt_mask = model.get_tgt_mask(sequence_length).to(device)\n",
        "        src_mask = model.create_pad_mask(X, 46).to(device)\n",
        "\n",
        "        pred = model(X, y_input, tgt_mask, src_mask)\n",
        "\n",
        "        pred = pred.permute(1, 2, 0)\n",
        "        loss = loss_fn(pred, y_expected)\n",
        "\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "        total_loss += loss.detach().item()\n",
        "\n",
        "    return total_loss / len(dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJQMfn1ok4g9"
      },
      "outputs": [],
      "source": [
        "def validation_loop(model, loss_fn, dataloader):\n",
        "\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            X, y = batch\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "            y_input = y[:,:-1]\n",
        "            y_expected = y[:,1:]\n",
        "\n",
        "            sequence_length = y_input.size(1)\n",
        "            tgt_mask = model.get_tgt_mask(sequence_length).to(device)\n",
        "            src_mask = model.create_pad_mask(X, 46).to(device)\n",
        "\n",
        "            pred = model(X, y_input, tgt_mask, src_mask)\n",
        "            pred = pred.permute(1, 2, 0)\n",
        "            loss = loss_fn(pred, y_expected)\n",
        "            total_loss += loss.detach().item()\n",
        "\n",
        "    return total_loss / len(dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxmUHtKBk93H"
      },
      "outputs": [],
      "source": [
        "def fit(model, opt, loss_fn, train_dataloader, val_dataloader, epochs):\n",
        "    train_loss_list, validation_loss_list = [], []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        train_loss = train_loop(model, opt, loss_fn, train_dataloader)\n",
        "        train_loss_list += [train_loss]\n",
        "\n",
        "        validation_loss = validation_loop(model, loss_fn, val_dataloader)\n",
        "        validation_loss_list += [validation_loss]\n",
        "\n",
        "        print(f\"ep: {epoch}, train loss: {train_loss:.4f}, val loss: {validation_loss:.4f}\")\n",
        "\n",
        "    return train_loss_list, validation_loss_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRGthEXThATJ",
        "outputId": "3530a5ef-a9ee-41e9-8ef3-a37b887740ac"
      },
      "outputs": [],
      "source": [
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "vocab_path = \"fen_vocab.json\"\n",
        "tar_vocab_path = \"vocab.json\"\n",
        "with open(vocab_path, \"r\") as f:\n",
        "    vocab = json.load(f)\n",
        "with open(tar_vocab_path, \"r\") as f:\n",
        "    tar_vocab = json.load(f)\n",
        "\n",
        "src_vocab_size = len(vocab.items()) + 1\n",
        "trg_vocab_size = len(tar_vocab.items()) + 1\n",
        "\n",
        "model = Transformer(\n",
        "    src_num_tokens=src_vocab_size, tar_num_tokens=trg_vocab_size, embed_size=128, num_heads=8, num_encoder_layers=5, num_decoder_layers=5, dropout_p=0.1\n",
        ").to(device)\n",
        "opt = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "train_loss_list, validation_loss_list = fit(model, opt, loss_fn, dataloader_train, dataloader_val, 10)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
